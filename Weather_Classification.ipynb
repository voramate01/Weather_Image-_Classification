{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2wMVmtYQsr1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12908,
     "status": "ok",
     "timestamp": 1588135740542,
     "user": {
      "displayName": "chase lee",
      "photoUrl": "",
      "userId": "12594108286739614963"
     },
     "user_tz": 240
    },
    "id": "0hBgVOv5Qsr4",
    "outputId": "1d3a6f83-82e8-4c01-dbb6-d3c07b68afe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWy-wJ8ERT-m"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQROGohlRUG2"
   },
   "outputs": [],
   "source": [
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15429,
     "status": "ok",
     "timestamp": 1588135913419,
     "user": {
      "displayName": "chase lee",
      "photoUrl": "",
      "userId": "12594108286739614963"
     },
     "user_tz": 240
    },
    "id": "mzJF-69gRUN0",
    "outputId": "3951d16e-b61a-4b36-f1a2-5fb623d35225"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIjKh0KVRufq"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/gdrive/My Drive/Colab Notebooks/dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lrmG6kv5Qsr7"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "f = []\n",
    "for file in os.listdir('.'):\n",
    "    if file.endswith('.jpg'):\n",
    "        f.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1588135943630,
     "user": {
      "displayName": "chase lee",
      "photoUrl": "",
      "userId": "12594108286739614963"
     },
     "user_tz": 240
    },
    "id": "7ZEXQ7SoQssB",
    "outputId": "20cbd479-084f-4d94-ad0d-759b80c638ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXIrEZWYQssD"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fS5AGoNdQssG"
   },
   "outputs": [],
   "source": [
    "df['img_name'] = np.array(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xU_z0bcsQssI"
   },
   "outputs": [],
   "source": [
    "# Create Label \n",
    "df['label'] = np.nan\n",
    "df['label'] = df['img_name'].apply(lambda x: x[0:6] if x.startswith('c') else\n",
    "                                             x[0:4] if x.startswith('r') else \n",
    "                                             x[0:7] if x.startswith('su') else\n",
    "                                             x[0:5] if x.startswith('sh') else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create foders to contain training, validation and tesing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_5K21TTQssN",
    "outputId": "23273598-9c12-4393-ff5f-5d019c67337e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /train\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /test\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /val\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(path+\"/\"+\"train\")\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path+\"/\"+\"train\")\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path+\"/\"+\"train\")\n",
    "try:\n",
    "    os.mkdir(path+\"/\"+\"test\")\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path+\"/\"+\"test\")\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path+\"/\"+\"test\")\n",
    "try:\n",
    "    os.mkdir(path+\"/\"+\"val\")\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path+\"/\"+\"val\")\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path+\"/\"+\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UF1RGLxFQssP"
   },
   "outputs": [],
   "source": [
    "list_label = df.label.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wep-aMy4QssS",
    "outputId": "c19bac36-1ff7-4371-929c-2f18b90aea1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /train/cloudy\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /train/rain\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /train/shine\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /train/sunrise\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /test/cloudy\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /test/rain\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /test/shine\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /test/sunrise\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /val/cloudy\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /val/rain\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /val/shine\n",
      "Successfully created the directory /home/vpasharawipas1/Deep/Weather_data /val/sunrise\n"
     ]
    }
   ],
   "source": [
    "for i in list_label:\n",
    "    try:\n",
    "        os.mkdir(path+\"/\"+\"train\"+\"/\"+i)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path+\"/\"+\"train\"+\"/\"+i)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path+\"/\"+\"train\"+\"/\"+i)\n",
    "for i in list_label:\n",
    "    try:\n",
    "        os.mkdir(path+\"/\"+\"test\"+\"/\"+i)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path+\"/\"+\"test\"+\"/\"+i)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path+\"/\"+\"test\"+\"/\"+i)\n",
    "for i in list_label:\n",
    "    try:\n",
    "        os.mkdir(path+\"/\"+\"val\"+\"/\"+i)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path+\"/\"+\"val\"+\"/\"+i)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path+\"/\"+\"val\"+\"/\"+i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy data to its appropiate folder based on the index after splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCvrOwlFQssV"
   },
   "outputs": [],
   "source": [
    "all_idx = [x for x in range(df.shape[0])]\n",
    "train_all_idx = list(np.random.choice(all_idx, int(len(all_idx)*0.8),replace = False))\n",
    "test_idx = list(set(all_idx) - set(train_all_idx))\n",
    "train_idx = list(np.random.choice(train_all_idx, int(len(train_all_idx)*0.8),replace = False))\n",
    "val_idx = list(set(train_all_idx) - set(train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9SoWJU8QssX"
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "for idx in train_idx:\n",
    "    src = path + '/' + df.iloc[idx]['img_name']\n",
    "    dst = path + '/' + 'train' + '/' + df.iloc[idx]['label'] + '/' + df.iloc[idx]['img_name']\n",
    "    copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TI7YBJk5QssZ"
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "for idx in test_idx:\n",
    "    src = path + '/' + df.iloc[idx]['img_name']\n",
    "    dst = path + '/' + 'test' + '/' + df.iloc[idx]['label'] + '/' + df.iloc[idx]['img_name']\n",
    "    copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "for idx in val_idx:\n",
    "    src = path + '/' + df.iloc[idx]['img_name']\n",
    "    dst = path + '/' + 'val' + '/' + df.iloc[idx]['label'] + '/' + df.iloc[idx]['img_name']\n",
    "    copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kLDh1CyQssb"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(path, 'train')\n",
    "validation_dir = os.path.join(path, 'val')\n",
    "test_dir = os.path.join(path, 'test')\n",
    "\n",
    "#Directory with our training set\n",
    "train_rain_dir = os.path.join(train_dir, 'rain')\n",
    "train_cloudy_dir = os.path.join(train_dir, 'cloudy')\n",
    "train_sunrise_dir = os.path.join(train_dir, 'sunrise')\n",
    "train_shine_dir = os.path.join(train_dir, 'shine')\n",
    "\n",
    "#Directory with our validation set\n",
    "validation_rain_dir = os.path.join(validation_dir, 'rain')\n",
    "validation_cloudy_dir = os.path.join(validation_dir, 'cloudy')\n",
    "validation_sunrise_dir = os.path.join(validation_dir, 'sunrise')\n",
    "validation_shine_dir = os.path.join(validation_dir, 'shine')\n",
    "\n",
    "#Directory with our testing set\n",
    "test_rain_dir = os.path.join(test_dir, 'rain')\n",
    "test_cloudy_dir = os.path.join(test_dir, 'cloudy')\n",
    "test_sunrise_dir = os.path.join(test_dir, 'sunrise')\n",
    "test_shine_dir = os.path.join(test_dir, 'shine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9759,
     "status": "ok",
     "timestamp": 1588135992023,
     "user": {
      "displayName": "chase lee",
      "photoUrl": "",
      "userId": "12594108286739614963"
     },
     "user_tz": 240
    },
    "id": "Uapdwn_AQssd",
    "outputId": "dabf0086-6c9a-46fb-998f-f9a28b6189fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training rain images: 139\n",
      "total training cloudy images: 193\n",
      "total training sunrise images: 236\n",
      "total training shine images: 149\n",
      "--\n",
      "total validation rain images: 29\n",
      "total validation cloudy images: 55\n",
      "total validation sunrise images: 56\n",
      "total validation shine images: 40\n",
      "--\n",
      "total test rain images: 45\n",
      "total test cloudy images: 52\n",
      "total test sunrise images: 64\n",
      "total test shine images: 64\n",
      "--\n",
      "Total training images: 717\n",
      "Total validation images: 180\n",
      "Total test images: 225\n"
     ]
    }
   ],
   "source": [
    "num_rain_tr = len(os.listdir(train_rain_dir))\n",
    "num_cloudy_tr = len(os.listdir(train_cloudy_dir))\n",
    "num_sunrise_tr = len(os.listdir(train_sunrise_dir))\n",
    "num_shine_tr = len(os.listdir(train_shine_dir))\n",
    "\n",
    "num_rain_val = len(os.listdir(validation_rain_dir))\n",
    "num_cloudy_val = len(os.listdir(validation_cloudy_dir))\n",
    "num_sunrise_val = len(os.listdir(validation_sunrise_dir))\n",
    "num_shine_val = len(os.listdir(validation_shine_dir))\n",
    "\n",
    "num_rain_test = len(os.listdir(test_rain_dir))\n",
    "num_cloudy_test = len(os.listdir(test_cloudy_dir))\n",
    "num_sunrise_test = len(os.listdir(test_sunrise_dir))\n",
    "num_shine_test = len(os.listdir(test_shine_dir))\n",
    "\n",
    "total_train = num_rain_tr + num_cloudy_tr + num_sunrise_tr + num_shine_tr\n",
    "total_val = num_rain_val + num_cloudy_val + num_sunrise_val + num_shine_val\n",
    "total_test = num_rain_test + num_cloudy_test + num_sunrise_test + num_shine_test\n",
    "\n",
    "print('total training rain images:', num_rain_tr)\n",
    "print('total training cloudy images:', num_cloudy_tr)\n",
    "print('total training sunrise images:', num_sunrise_tr)\n",
    "print('total training shine images:', num_shine_tr)\n",
    "print(\"--\")\n",
    "print('total validation rain images:', num_rain_val)\n",
    "print('total validation cloudy images:', num_cloudy_val)\n",
    "print('total validation sunrise images:', num_sunrise_val)\n",
    "print('total validation shine images:', num_shine_val)\n",
    "print(\"--\")\n",
    "print('total test rain images:', num_rain_test)\n",
    "print('total test cloudy images:', num_cloudy_test)\n",
    "print('total test sunrise images:', num_sunrise_test)\n",
    "print('total test shine images:', num_shine_test)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)\n",
    "print(\"Total test images:\", total_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6X2YD5GuQss3"
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.applications import VGG16\n",
    "#from keras.preprocessing import image\n",
    "IMAGE_SIZE = [256, 256]  \n",
    "# we will keep the image size as (256,256). You can increase the size for better results. \n",
    "\n",
    "# loading the weights of VGG16 without the top layer. \n",
    "#These weights are trained on Imagenet dataset.\n",
    "vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  \n",
    "# input_shape = (256,256,3) as required by VGG\n",
    "\n",
    "# this will exclude the initial layers from training phase as there are already been trained.\n",
    "for layer in vgg.layers[:-8]:\n",
    "    layer.trainable = False\n",
    "for layer in vgg.layers[-8:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
    "pred = Dense(4, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = pred)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12167,
     "status": "ok",
     "timestamp": 1588136135944,
     "user": {
      "displayName": "chase lee",
      "photoUrl": "",
      "userId": "12594108286739614963"
     },
     "user_tz": 240
    },
    "id": "zJS3dtDFQss6",
    "outputId": "a8b985a0-2f75-4e87-ccb3-152cc6e7da75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 18,909,636\n",
      "Trainable params: 17,174,148\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the VGG layer status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1588136150220,
     "user": {
      "displayName": "chase lee",
      "photoUrl": "",
      "userId": "12594108286739614963"
     },
     "user_tz": 240
    },
    "id": "MncC5SujQss8",
    "outputId": "5c6b74aa-6ee5-41a9-85da-965aeab3d9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 717 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 225 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "                                    rescale=1./255,   # all pixel values will be between 0 an 1\n",
    "                                    shear_range=0.2, \n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    preprocessing_function=preprocess_input)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(train_dir, target_size = IMAGE_SIZE, batch_size = 100, class_mode = 'categorical')\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = IMAGE_SIZE, batch_size = 100, class_mode = 'categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size = IMAGE_SIZE, batch_size = 100, class_mode = 'categorical',shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "6hZ_fi9VQss-",
    "outputId": "7011818f-0403-4658-f21d-fb225971ccea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "717/717 [==============================] - 938s 1s/step - loss: 0.2135 - acc: 0.9202 - val_loss: 0.7213 - val_acc: 0.8667\n",
      "Epoch 2/2\n",
      "717/717 [==============================] - 921s 1s/step - loss: 0.0466 - acc: 0.9871 - val_loss: 0.2815 - val_acc: 0.9500\n"
     ]
    }
   ],
   "source": [
    "training_images = 717 \n",
    "validation_images = 180\n",
    "history = model.fit_generator(training_generator,\n",
    "                   steps_per_epoch = 717,  # this should be equal to total number of images in training set. But to speed up the execution, I am only using 10000 images. Change this for better results. \n",
    "                   epochs = 2,  # change this for better results\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = 180)  # this should be equal to total number of images in validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmiTI3jQQstB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = [0.9194253161595908, 0.9872489537978199]\n",
      "Validation Accuracy = [0.8666666679912143, 0.9499999947018094]\n"
     ]
    }
   ],
   "source": [
    "print ('Training Accuracy = ' + str(history.history['acc']))\n",
    "print ('Validation Accuracy = ' + str(history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ip6m0XY9St5R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('dl_fcl_v2.h5')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3t4lvx5SyUW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load saved models\n",
    "from keras.models import load_model\n",
    "image_cnn = load_model('dl_fcl_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance -VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[43  0  5  4]\n",
      " [ 0 42  2  1]\n",
      " [ 1  1 61  1]\n",
      " [ 0  0  1 63]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cloud       0.98      0.83      0.90        52\n",
      "        rain       0.98      0.93      0.95        45\n",
      "       shine       0.88      0.95      0.92        64\n",
      "     sunrise       0.91      0.98      0.95        64\n",
      "\n",
      "    accuracy                           0.93       225\n",
      "   macro avg       0.94      0.92      0.93       225\n",
      "weighted avg       0.93      0.93      0.93       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#Confusion Matrix and Classification Report\n",
    "Y_pred = image_cnn.predict_generator(test_generator, test_generator.samples // test_generator.batch_size + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "lables=['cloud','rain','shine','sunrise']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=lables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN (customized layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 717 images belonging to 4 classes.\n",
      "Found 180 images belonging to 4 classes.\n",
      "Found 225 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "                                    rescale=1./255,   # all pixel values will be between 0 an 1\n",
    "                                    shear_range=0.2, \n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    preprocessing_function=preprocess_input)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(train_dir, target_size = IMAGE_SIZE\n",
    "                                                          , batch_size =717, class_mode = 'categorical')\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = IMAGE_SIZE\n",
    "                                                              , batch_size = 180, class_mode = 'categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size = IMAGE_SIZE\n",
    "                                                  , batch_size = 225, class_mode = 'categorical',shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print(training_generator[0][0][0].shape)\n",
    "print(training_generator[0][1][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting up the features and lables to be suitable for TFLEARN'''\n",
    "# X-Features & Y-Labels \n",
    "X = training_generator[0][0]\n",
    "Y = training_generator[0][1] \n",
    "mytest_x = validation_generator[0][0]\n",
    "mytest_y = validation_generator[0][1]\n",
    "mytest_holdout_x = test_generator[0][0]\n",
    "mytest_holdout_y = test_generator[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn \n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
    "from tflearn.layers.core import input_data, dropout, fully_connected \n",
    "from tflearn.layers.estimator import regression \n",
    "import tensorflow as tf\n",
    "LR = 1e-3\n",
    "tf.reset_default_graph() \n",
    "convnet = input_data(shape =[None, 256 , 256 , 3], name ='input') # input (none, image heigt, image width, 3)\n",
    "  \n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "  \n",
    "convnet = conv_2d(convnet, 64, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "  \n",
    "convnet = conv_2d(convnet, 128, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "  \n",
    "convnet = conv_2d(convnet, 64, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "  \n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu') \n",
    "convnet = max_pool_2d(convnet, 5) \n",
    "  \n",
    "convnet = fully_connected(convnet, 1024, activation ='relu') \n",
    "convnet = dropout(convnet, 0.8) \n",
    "  \n",
    "convnet = fully_connected(convnet, 4, activation ='softmax') # 4 is number of class\n",
    "convnet = regression(convnet, optimizer ='adam', learning_rate = LR, \n",
    "      loss ='categorical_crossentropy', name ='targets') \n",
    "  \n",
    "model = tflearn.DNN(convnet, tensorboard_dir ='log') \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.05171\u001b[0m\u001b[0m | time: 30.411s\n",
      "| Adam | epoch: 035 | loss: 0.05171 - acc: 0.9889 -- iter: 704/717\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.04747\u001b[0m\u001b[0m | time: 35.224s\n",
      "| Adam | epoch: 035 | loss: 0.04747 - acc: 0.9900 | val_loss: 0.15360 - val_acc: 0.9611 -- iter: 717/717\n",
      "--\n",
      "Time used:  21.236554809411366  mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch = 35,  \n",
    "    validation_set =({'input': mytest_x}, {'targets': mytest_y}),  \n",
    "    snapshot_step = 5, show_metric = True, run_id = 'MODEL_NAME') \n",
    "stop = time.time()\n",
    "print(\"Time used: \", (stop-start)/60, \" mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.12304\u001b[0m\u001b[0m | time: 30.264s\n",
      "| Adam | epoch: 025 | loss: 0.12304 - acc: 0.9594 -- iter: 704/717\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.11148\u001b[0m\u001b[0m | time: 35.088s\n",
      "| Adam | epoch: 025 | loss: 0.11148 - acc: 0.9634 | val_loss: 0.28713 - val_acc: 0.9111 -- iter: 717/717\n",
      "--\n",
      "Time used:  15.095795277754466  mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch = 25,  \n",
    "    validation_set =({'input': mytest_x}, {'targets': mytest_y}),  \n",
    "    snapshot_step = 5, show_metric = True, run_id = 'MODEL_NAME') \n",
    "stop = time.time()\n",
    "print(\"Time used: \", (stop-start)/60, \" mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.03713\u001b[0m\u001b[0m | time: 32.856s\n",
      "| Adam | epoch: 080 | loss: 0.03713 - acc: 0.9966 -- iter: 704/717\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.03393\u001b[0m\u001b[0m | time: 37.579s\n",
      "| Adam | epoch: 080 | loss: 0.03393 - acc: 0.9969 | val_loss: 0.13869 - val_acc: 0.9667 -- iter: 717/717\n",
      "--\n",
      "Time used:  48.18629100322723  mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch = 80,  \n",
    "    validation_set =({'input': mytest_x}, {'targets': mytest_y}),  \n",
    "    snapshot_step = 5, show_metric = True, run_id = 'MODEL_NAME') \n",
    "stop = time.time()\n",
    "print(\"Time used: \", (stop-start)/60, \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/home/vpasharawipas1/Deep/Weather_data/cnn_customized is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "###save the model\n",
    "model.save(\"cnn_customized\") \n",
    "###To Load trained model \n",
    "#model.load('cnn_customized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance - customized CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[48  0  2  0]\n",
      " [ 0 44  1  0]\n",
      " [ 4  2 50  1]\n",
      " [ 0  0  0 73]]\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      cloud       0.92      0.96      0.94        50\n",
      "       rain       0.96      0.98      0.97        45\n",
      "      shine       0.94      0.88      0.91        57\n",
      "    sunrise       0.99      1.00      0.99        73\n",
      "\n",
      "avg / total       0.96      0.96      0.96       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#Confusion Matrix and Classification Report\n",
    "y_pred=model.predict(mytest_holdout_x)\n",
    "y_pred= [ np.argmax(i)  for i in y_pred ]\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "lables=['cloud','rain','shine','sunrise']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=lables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[42  2  8  0]\n",
      " [ 3 41  1  0]\n",
      " [ 4  1 58  1]\n",
      " [ 0  0  0 64]]\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      cloud       0.86      0.81      0.83        52\n",
      "       rain       0.93      0.91      0.92        45\n",
      "      shine       0.87      0.91      0.89        64\n",
      "    sunrise       0.98      1.00      0.99        64\n",
      "\n",
      "avg / total       0.91      0.91      0.91       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#Confusion Matrix and Classification Report\n",
    "y_pred=model.predict(mytest_holdout_x)\n",
    "y_pred= [ np.argmax(i)  for i in y_pred ]\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "lables=['cloud','rain','shine','sunrise']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=lables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[48  1  3  0]\n",
      " [ 4 41  0  0]\n",
      " [ 8  0 55  1]\n",
      " [ 0  0  0 64]]\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      cloud       0.80      0.92      0.86        52\n",
      "       rain       0.98      0.91      0.94        45\n",
      "      shine       0.95      0.86      0.90        64\n",
      "    sunrise       0.98      1.00      0.99        64\n",
      "\n",
      "avg / total       0.93      0.92      0.93       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#Confusion Matrix and Classification Report\n",
    "y_pred=model.predict(mytest_holdout_x)\n",
    "y_pred= [ np.argmax(i)  for i in y_pred ]\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "lables=['cloud','rain','shine','sunrise']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=lables))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DL_FINAL2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
